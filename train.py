from env import SnakeEnv
from agent import Agent
import matplotlib.pyplot as plt
import numpy as np

def plot(scores, mean_scores):
    plt.clf()
    plt.title('Training...')
    plt.xlabel('Game')
    plt.ylabel('Score')
    plt.plot(scores)
    plt.plot(mean_scores)
    plt.legend(['Score', 'Mean Score'])
    plt.pause(0.1)

def train():
    print("train start")
    try:
        env = SnakeEnv()
        agent = Agent()
        
        scores = []
        mean_scores = []
        total_score = 0
        print("âœ… í™˜ê²½ê³¼ ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print("âŒ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
        return


    for game in range(1, 1001):  # ì—í”¼ì†Œë“œ ìˆ˜
        print(f"game {game}ì‹œì‘")
        state = env.reset()
        print("ğŸ” state shape:", np.shape(state))
        done = False
        score = 0

        while not done:
            action = agent.get_action(state)
            next_state, reward, done = env.step(action)

            # ë‹¨ê¸° í•™ìŠµ
            agent.train_short_memory(state, action, reward, next_state, done)

            # ê²½í—˜ ì €ì¥
            agent.remember(state, action, reward, next_state, done)

            state = next_state
            env.render(fps=30)
            score += reward

            # ì‹œê°í™” (ì„ íƒ)
            # env.render()

        # ê²Œì„ ëë‚˜ë©´ ì¥ê¸° í•™ìŠµ
        agent.train_long_memory()
        agent.n_games += 1

        scores.append(score)
        total_score += score
        mean_score = total_score / agent.n_games
        mean_scores.append(mean_score)

        print(f"Game {agent.n_games} â†’ Score: {score:.1f} | Mean: {mean_score:.2f}")

        if agent.n_games % 20 == 0:
            plot(scores, mean_scores)

if __name__ == '__main__':
    train()